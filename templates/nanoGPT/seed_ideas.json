[
  {
      "Name": "adaptive_sparse_self_attention",
      "Title": "Adaptive Sparse Self-Attention: Dynamic Token Selection for Efficiency",
      "Experiment": "Develop an adaptive self-attention mechanism where sparsity is learned dynamically for each input. Compare computational efficiency and accuracy against standard self-attention.",
      "Interestingness": 9,
      "Feasibility": 8,
      "Novelty": 9,
      "novel": true
  },
  {
      "Name": "transformer_hierarchical_sparsity",
      "Title": "Hierarchical Sparsity in Transformers: Learning Multi-Scale Sparse Representations",
      "Experiment": "Introduce multi-scale sparsity constraints in transformer layers to mimic hierarchical data structures. Test the model's performance on structured datasets like graphs and hierarchical text.",
      "Interestingness": 9,
      "Feasibility": 7,
      "Novelty": 8,
      "novel": true
  }
]
